{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshnaidu999/sentiment-analysis-on-amazon-fine-food-review/blob/main/Final_Seq2SeqImplementation__Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYHE_1ck2az"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
        "\n",
        "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
        " so do read the references completly and after that only please check the internet.\n",
        " The best things is to read the research papers and try to implement it on your own. \n",
        "\n",
        "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
        "\n",
        "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
        " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
        "with out learning much and didn't spend your time productively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. You have to implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "6.  a. Check the reference notebook <br>\n",
        "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4n4XUP-QET2",
        "outputId": "8f8d3dea-714d-481d-dfbd-8ff7d3dcb93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-07-08 16:50:32--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.21.55.222, 2606:4700:3036::ac43:adc6, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7692825 (7.3M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   7.34M  13.6MB/s    in 0.5s    \n",
            "\n",
            "2021-07-08 16:50:33 (13.6 MB/s) - ‘ita-eng.zip’ saved [7692825/7692825]\n",
            "\n",
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "#loding the data  Data loading is the process of copying and loading data or data sets from a source file, folder or application to a database\n",
        "!wget http://www.manythings.org/anki/ita-eng.zip\n",
        "!unzip ita-eng.zip  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU80Ao-AGaob"
      },
      "outputs": [],
      "source": [
        "#importing the required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#importing the required libraries\n",
        "import re\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#importing the required libraries\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#opeining the file in read mode\n",
        "#with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "  #  eng=[]\n",
        "   # ita=[]\n",
        "    \"\"\"for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "#converting the data to data frames and loading the data\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#opeining the file in read mode\n",
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#converting the data to data frames and loading the data\n",
        "df_data = pd.DataFrame(data=list(zip(eng, ita)), \n",
        "                        columns=['english','italian'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Fjtic103QSci",
        "outputId": "8ed2de15-afcd-48e1-ae6e-b34a27f81039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(350360, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#to print the shape of the data\n",
        "print(df_data.shape)\n",
        "\n",
        "df_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decontractions(data_phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    data_phrase = re.sub(r\"won\\'t\", \"will not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"can\\'t\", \"can not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"won\\’t\", \"will not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"can\\’t\", \"can not\", data_phrase)\n",
        "\n",
        "     \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # general\n",
        "    data_phrase = re.sub(r\"n\\'t\", \" not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'re\", \" are\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'s\", \" is\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'d\", \" would\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'ll\", \" will\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'t\", \" not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'ve\", \" have\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\'m\", \" am\", data_phrase)\n",
        "\n",
        " \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    data_phrase = re.sub(r\"n\\’t\", \" not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\’re\", \" are\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\’s\", \" is\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\’d\", \" would\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\’ll\", \" will\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\’t\", \" not\", data_phrase)\n",
        "\n",
        "    data_phrase = re.sub(r\"\\’ve\", \" have\", data_phrase)\n",
        "    \n",
        "    data_phrase = re.sub(r\"\\’m\", \" am\", data_phrase)\n",
        "\n",
        "    return data_phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(pre_text):\n",
        "    \n",
        "    # convert all the text into lower letters\n",
        "\n",
        "    pre_text = pre_text.lower()\n",
        "\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "\n",
        "    pre_text = decontractions(pre_text)\n",
        "        \n",
        "    # remove all the spacial characters: except space ' '\n",
        "\n",
        "    pre_text = re.sub('[^A-Za-z0-9 ]+', '', pre_text)\n",
        "\n",
        "    return pre_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_ita(pre_ita_text):\n",
        "\n",
        "    # convert all the text into lower letters\n",
        "\n",
        "    pre_ita_text = pre_ita_text.lower()\n",
        "\n",
        "     # remove the words betweent brakets ()\n",
        "\n",
        "    pre_ita_text = decontractions(pre_ita_text)\n",
        "\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "\n",
        "    pre_ita_text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', pre_ita_text)\n",
        "\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "\n",
        "    pre_ita_text = re.sub('\\u200b', ' ', pre_ita_text)\n",
        "\n",
        "    pre_ita_text = re.sub('\\xa0', ' ', pre_ita_text)\n",
        "\n",
        "    pre_ita_text = re.sub('-', ' ', pre_ita_text)\n",
        "    \n",
        "    return pre_ita_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9QqElB_nKZos",
        "outputId": "a82739c5-8e79-4975-8f57-36f9eede54d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_data['english'] = df_data['english'].apply(preprocess)\n",
        "\n",
        "df_data['italian'] = df_data['italian'].apply(preprocess_ita)\n",
        "\n",
        "df_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data['italian_len'] = df_data['italian'].str.split().apply(len)\n",
        "\n",
        "df_data = df_data[df_data['italian_len'] < 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data['english_len'] = df_data['english'].str.split().apply(len)\n",
        "\n",
        "df_data = df_data[df_data['english_len'] < 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data['english_inp'] = '<start> ' + df_data['english'].astype(str)\n",
        "\n",
        "df_data['english_out'] = df_data['english'].astype(str) + ' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_data = df_data.drop(['english','italian_len','english_len'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ir9TPl60ajSi",
        "outputId": "87acbaa0-f27b-4837-bccc-c4f77f4d0f55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "df_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prrcu1PUusZ_"
      },
      "source": [
        "## Data Preparation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pU-yY-gus3C"
      },
      "outputs": [],
      "source": [
        "#impporting required libraris\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(df_data, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_WQrfRzus5W",
        "outputId": "40a16419-25b5-4901-a1f9-b8be5c0acb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(279900, 3) (69975, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_data.shape, test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train_data.iloc[0]['english_inp']= str(train_data.iloc[0]['english_inp'])+' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "traitrain_datan.iloc[0]['english_out']= str(train_data.iloc[0]['english_out'])+' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYByD4MMus7g"
      },
      "outputs": [],
      "source": [
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "# tokenization\n",
        "toknizer_ita = Tokenizer() \n",
        "\n",
        "toknizer_ita.fit_on_texts(train_data['italian'].values)\n",
        "\n",
        "toknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "\n",
        "toknizer_eng.fit_on_texts(train_data['english_inp'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngujdboLus-G",
        "outputId": "2611e26b-fd67-4f81-d437-3d752541426e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12990\n",
            "26506\n"
          ]
        }
      ],
      "source": [
        " # vocab size of english corpus\n",
        "vocabularry_size_eng = len(toknizer_eng.word_index.keys())     # vocab size of english corpus\n",
        "\n",
        "print(vocabularry_size_eng)\n",
        "\n",
        "\n",
        "# vocab size of italian corpus\n",
        "vocabularry_size_ita = len(toknizer_ita.word_index.keys())     # vocab size of italian corpus\n",
        "\n",
        "print(vocabularry_size_ita)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f86Vu_QrutAa",
        "outputId": "bde5830b-11b1-4d21-e28a-e4d661924b9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 10236)"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vocab size of english corpus# vocab size of english corpus\n",
        "toknizer_eng.word_index['<start>'], toknizer_eng.word_index['<end>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cex2XfCLOew"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs, encoder_final_state_h, encoder_final_state_c\n",
        "    ''''''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs, encoder_final_state_h, encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):    \n",
        "        super(Encoder, self).__init__()    # initializing encoder\n",
        "        self.lstm_size = lstm_size                       \n",
        "        self.input_length = input_length\n",
        "        self.embedding_size =embedding_size\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        \n",
        "        #Initialize Embedding layer\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length)\n",
        "        \n",
        "        #Intialize Encoder LSTM layer\n",
        "         #Intialize Encoder LSTM layer\n",
        "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_sequences=True, return_state=True)\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "        '''\n",
        "            Given a batch size it will return intial hidden state and intial cell state.\n",
        "            If batch size is 32- Hidden state is zeros of size [32, lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        ''' \n",
        "        return (tf.zeros([batch_size, self.lstm_size]), tf.zeros([batch_size, self.lstm_size]))   # intialize the encoder input state \n",
        "        '''\n",
        "            Given a batch size it will return intial hidden state and intial cell state.\n",
        "            If batch size is 32- Hidden state is zeros of size [32, lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        ''' \n",
        "\n",
        "\n",
        "    def call(self, input_sequence, states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "\n",
        "\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        data_embed_enc = self.embedding(input_sequence)      # embed the input sequence\n",
        "\n",
        "        output, state_h, state_c = self.lstm(data_embed_enc, initial_state=states)    # get the output of the encoder \n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    \n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziSqOgmhLOe1",
        "outputId": "b837caea-ac4f-4e12-c31d-e267f42bb0b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size, embedding_size, lstm_size, input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length], maxval=vocab_size, minval=0, dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output, state_h, state_c=encoder(input_sequence, initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size, lstm_size) and state_c.shape==(batch_size, lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ES1-sJLOe4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self, out_vocab_size, emb_size, lstm_size, input_length):\n",
        "        \"\"\"super(Decoder, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.input_length = input_length\n",
        "        self.emb_size = emb_size\"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "\n",
        "        \n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.input_length = input_length\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=self.out_vocab_size, output_dim=self.emb_size, input_length=self.input_length)\n",
        "        #Intialize Decoder LSTM layer\n",
        "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_sequences=True, return_state=True)\n",
        "        \n",
        "    def call(self, input_sequence, initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "        \n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        data_embed = self.embedding(input_sequence)\n",
        "        \n",
        "        lstm_out, state_h, state_c = self.lstm(data_embed, initial_states) \n",
        "        \n",
        "        return lstm_out, state_h, state_c  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B0gokgKLOe8",
        "outputId": "4bd6c642-edb0-413d-d3cf-f8fa8f6ab2b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size, input_length, dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size, dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size, dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units, input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size, input_length, dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvLu1kgEzd-v"
      },
      "source": [
        "## Creating data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ7L-B7qzhGV"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, df_data, toknizer_ita, toknizer_eng, maximum_len):\n",
        "\n",
        "        self.encoder_inps = df_data['italian'].values\n",
        "        self.decoder_inps = df_data['english_inp'].values\n",
        "        \"\"\"self.encoder_inps = df_data['italian'].values\n",
        "        self.decoder_inps = df_data['english_inp'].values\n",
        "        self.decoder_outs = df_data['english_out'].values\n",
        "        self.toknizer_eng = toknizer_eng\n",
        "        self.toknizer_ita = toknizer_ita\n",
        "        self.maximum_len = maximum_len\"\"\"\n",
        "        self.decoder_outs = df_data['english_out'].values\n",
        "        self.toknizer_eng = toknizer_eng\n",
        "        self.toknizer_ita = toknizer_ita\n",
        "        self.maximum_len = maximum_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.toknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "\n",
        "        self.decoder_inp_seq = self.toknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "\n",
        "        self.decoder_out_seq = self.toknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, \n",
        "                                            maxlen=self.maximum_len, \n",
        "                                            dtype='int32', \n",
        "                                            padding='post')\n",
        "\n",
        "        \"\"\"self.encoder_seq = pad_sequences(self.encoder_seq, \n",
        "                                            maxlen=self.maximum_len, \n",
        "                                            dtype='int32', \n",
        "                                            padding='post')\"\"\"                                    \n",
        "\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, \n",
        "                                            maxlen=self.maximum_len, \n",
        "                                            dtype='int32', \n",
        "                                            padding='post')\n",
        "\n",
        "        \"\"\"self.encoder_seq = pad_sequences(self.encoder_seq, \n",
        "                                            maxlen=self.maximum_len, \n",
        "                                            dtype='int32', \n",
        "                                            padding='post')\"\"\"     \n",
        "\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, \n",
        "                                            maxlen=self.maximum_len, \n",
        "                                            dtype='int32', \n",
        "                                            padding='post')\n",
        "\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, final_data_set, batch_size=1):\n",
        "        self.final_data_set = final_data_set\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.final_data_set.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.final_data_set[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "\n",
        "\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "\n",
        "        \n",
        "        return tuple([[batch[0], batch[1]], batch[2]])\n",
        "\n",
        "    \"\"\"def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\"\"\"\n",
        "\n",
        "    # your model.fit_gen requires this function\n",
        "    \n",
        "    def __len__(self):  \n",
        "\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    \"\"\"def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)\"\"\"\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"class Encoder_decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, encoder_inputs_length, decoder_inputs_length, output_vocab_size):\n",
        "        super(Encoder_decoder, self).__init__()\n",
        "        self.encoder_inputs_length = encoder_inputs_length\n",
        "        self.decoder_inputs_length = decoder_inputs_length\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        #Create encoder object\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, input_length=self.encoder_inputs_length, lstm_size=128)\n",
        "        #Create decoder object\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_size=50, input_length=self.decoder_inputs_length, lstm_size=128)\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.dense = Dense(self.output_vocab_size, activation='softmax')\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "final_train_dataset = Dataset(train, toknizer_ita, toknizer_eng, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_test_dataset  = Dataset(test, tknizer_ita, tknizer_eng, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_train_dataloader = Dataloder(final_train_dataset, batch_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_test_dataloader = Dataloder(final_test_dataset, batch_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OoGj5yszhJO",
        "outputId": "1420e66e-e0f0-416f-bcfb-4a84fc411de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1024, 20) (1024, 20) (1024, 20)\n"
          ]
        }
      ],
      "source": [
        "print(final_train_dataloader[0][0][0].shape, final_train_dataloader[0][0][1].shape, final_train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"class Encoder_decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, encoder_inputs_length, decoder_inputs_length, output_vocab_size):\n",
        "        super(Encoder_decoder, self).__init__()\n",
        "        self.encoder_inputs_length = encoder_inputs_length\n",
        "        self.decoder_inputs_length = decoder_inputs_length\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        #Create encoder object\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, input_length=self.encoder_inputs_length, lstm_size=128)\n",
        "        #Create decoder object\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_size=50, input_length=self.decoder_inputs_length, lstm_size=128)\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.dense = Dense(self.output_vocab_size, activation='softmax')\n",
        "    \n",
        "    def call(self, data):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output, encoder_final_state_h, encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h, encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        initial_state = self.encoder.initialize_states(1024) \n",
        "\n",
        "        input, output = data[0], data[1]                \n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input, states=initial_state)\n",
        "        initial_state = [encoder_h, encoder_c]\n",
        "        decoder_output ,_ , _ = self.decoder(output, initial_state)\n",
        "        output = self.dense(decoder_output)   \n",
        "        return output \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, enc_inputs_length, dec_inputs_length, output_vocab_size):\n",
        "        super(Encoder_decoder, self).__init__()\n",
        "        self.enc_inputs_length = enc_inputs_length\n",
        "        self.dec_inputs_length = dec_inputs_length\n",
        "        \"\"\"self.enc_inputs_length = enc_inputs_length\n",
        "        self.dec_inputs_length = dec_inputs_length\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        \"\"\"\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "\n",
        "\n",
        "        #Create encoder object\n",
        "\n",
        "        self.encoder_data = Encoder(inp_vocab_size=vocab_size_ita+1, \n",
        "                                    embedding_size=50, \n",
        "                                    input_length=self.enc_inputs_length, \n",
        "                                    lstm_size=128)\n",
        "        #Create decoder object\n",
        "         \"\"\"input, output = data[0], data[1]                \n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input, states=initial_state)\n",
        "        initial_state = [encoder_h, encoder_c]\n",
        "        decoder_output ,_ , _ = self.decoder(output, initial_state)\n",
        "        output = self.dense(decoder_output)  \n",
        "        \"\"\"\n",
        "        self.decoder_data = Decoder(out_vocab_size=vocab_size_eng+1, \n",
        "                                    embedding_size=50, \n",
        "                                    input_length=self.dec_inputs_length, \n",
        "                                    lstm_size=128)\n",
        "        \n",
        "        \n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.dense = Dense(self.output_vocab_size, activation='softmax')\n",
        "    \n",
        "    def call(self, final_data):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output, encoder_final_state_h, encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h, encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        initial_state = self.encoder.initialize_states(1024) \n",
        "\n",
        "        input, output = final_data[0], final_data[1]  \n",
        "\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input, states=initial_state)\n",
        "\n",
        "\n",
        "        initial_state = [encoder_h, encoder_c]\n",
        "\n",
        "        decoder_data_output ,_ , _ = self.decoder(output, initial_state)\n",
        "        data_output = self.dense(decoder_data_output)   \n",
        "        return data_output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcL61dJXLOfB",
        "outputId": "2a0d0d40-61c1-47a3-e545-63f1bd8f1a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "273/273 [==============================] - 60s 211ms/step - loss: 2.6373 - val_loss: 1.7395\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 1.6386 - val_loss: 1.5611\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 1.5100 - val_loss: 1.4413\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 1.3581 - val_loss: 1.2714\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 1.2080 - val_loss: 1.1463\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 1.1005 - val_loss: 1.0479\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 1.0142 - val_loss: 0.9666\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 57s 209ms/step - loss: 0.9348 - val_loss: 0.8900\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 57s 209ms/step - loss: 0.8600 - val_loss: 0.8187\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.7897 - val_loss: 0.7452\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.7231 - val_loss: 0.6842\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 56s 204ms/step - loss: 0.6622 - val_loss: 0.6232\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 0.6073 - val_loss: 0.5714\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 56s 205ms/step - loss: 0.5587 - val_loss: 0.5275\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.5147 - val_loss: 0.4854\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.4755 - val_loss: 0.4470\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 56s 205ms/step - loss: 0.4406 - val_loss: 0.4138\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.4097 - val_loss: 0.3857\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.3824 - val_loss: 0.3598\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.3576 - val_loss: 0.3367\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.3361 - val_loss: 0.3167\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 0.3162 - val_loss: 0.2980\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.2985 - val_loss: 0.2825\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 0.2827 - val_loss: 0.2657\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 57s 209ms/step - loss: 0.2684 - val_loss: 0.2519\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 0.2552 - val_loss: 0.2408\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 56s 205ms/step - loss: 0.2434 - val_loss: 0.2286\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 56s 203ms/step - loss: 0.2323 - val_loss: 0.2184\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.2217 - val_loss: 0.2089\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 56s 205ms/step - loss: 0.2123 - val_loss: 0.1993\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.2037 - val_loss: 0.1924\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1958 - val_loss: 0.1830\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1883 - val_loss: 0.1762\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 56s 203ms/step - loss: 0.1813 - val_loss: 0.1723\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.1749 - val_loss: 0.1639\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1690 - val_loss: 0.1584\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 56s 205ms/step - loss: 0.1630 - val_loss: 0.1545\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 0.1583 - val_loss: 0.1495\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.1529 - val_loss: 0.1440\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1483 - val_loss: 0.1394\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.1438 - val_loss: 0.1372\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 56s 207ms/step - loss: 0.1400 - val_loss: 0.1325\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 56s 204ms/step - loss: 0.1360 - val_loss: 0.1280\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 57s 207ms/step - loss: 0.1324 - val_loss: 0.1234\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 57s 208ms/step - loss: 0.1286 - val_loss: 0.1202\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1255 - val_loss: 0.1177\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1222 - val_loss: 0.1139\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1188 - val_loss: 0.1116\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 56s 206ms/step - loss: 0.1163 - val_loss: 0.1095\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 56s 205ms/step - loss: 0.1134 - val_loss: 0.1063\n",
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_1 (Encoder)          multiple                  1414498   \n",
            "_________________________________________________________________\n",
            "decoder_1 (Decoder)          multiple                  741798    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  1677258   \n",
            "=================================================================\n",
            "Total params: 3,833,554\n",
            "Trainable params: 3,833,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "model  = Encoder_decoder(encoder_inputs_length=20, \n",
        "                        decoder_inputs_length=20, \n",
        "                        output_vocab_size=vocab_size_eng)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "\"\"\"# Compile the model and fit the model\n",
        "model  = Encoder_decoder(encoder_inputs_length=20,  decoder_inputs_length=20, output_vocab_size=vocab_size_eng)\"\"\"\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "train_steps = train.shape[0]//1024\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_steps = test.shape[0]//1024\n",
        "\n",
        "\n",
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "model.fit(train_dataloader, \n",
        "            steps_per_epoch=train_steps, \n",
        "            epochs=50, \n",
        "            validation_data=train_dataloader, \n",
        "            validation_steps=test_steps)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkARSlZgLOfE"
      },
      "outputs": [],
      "source": [
        "def predict(data_input_sentence):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "    final_test_source_seq = toknizer_ita.texts_to_sequences([data_input_sentence])\n",
        "    \n",
        "    data_encoder = model.layers[0]    # encoder\n",
        "\n",
        "\n",
        "    data_decoder = model.layers[1]    # decoder\n",
        "    dense = model.layers[2]      # dense layer\n",
        "\n",
        "    # initialize encoder state for one sequence # initialize encoder state for one sequence \n",
        "    en_initial_states = data_encoder.initialize_states(1)      # initialize encoder state for one sequence \n",
        "    \n",
        "    \n",
        "    # encoder output shape# encoder output shape\n",
        "    en_outputs = data_encoder(tf.constant(test_source_seq), en_initial_states)      \n",
        "\n",
        "    de_final_input = tf.constant([[toknizer_eng.word_index['<start>']]])   # int of '<start>' token \n",
        "\n",
        "    de_final_state_h, de_final_state_c = en_outputs[1:]   # hidden states of encoder \n",
        "\n",
        "    ''' A. Given input sentence, convert the sentence into integers using tokenizer used earlier B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder D. till we reach max_length of decoder or till the model predicted word <end>: predicted_out,state_h,state_c=model.layers[1](dec_input,states) pass the predicted_out to the dense layer update the states=[state_h,state_c] And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string. Update the input_to_decoder with current predictions F. Return the predicted sentence '''\n",
        "    out_words = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        de_final_output, de_final_state_h, de_final_state_c = decoder(de_input, [de_final_state_h, de_final_state_c])   \n",
        "        # given first word and hidden state to the decoder give decoder o/p and hidden state \n",
        "\n",
        "\n",
        "        de_final_output = dense(de_final_output)            # o/p of decoder is passed to dense layer having softmax activation \n",
        "\n",
        "\n",
        "        de_final_input = tf.argmax(de_final_output, -1)      # get the index of the max values of the dense layer\n",
        "\n",
        "        if de_input.numpy()[0][0] == 0:          # if its first index append noting\n",
        "            data_out_words.append('')    \n",
        "        else:# get the word corresponding to the highest index and append it to out_words \n",
        "            data_out_words.append(tknizer_eng.index_word[de_final_input.numpy()[0][0]])   \n",
        "            \n",
        "\n",
        "        if data_out_words[-1] == '<end>' or len(data_out_words) >= 20:     # if last word is '<end>' or len(out_words)>20 break\n",
        "            break\n",
        "\n",
        "    return ' '.join(out_data_out_wordswords)   # join all the words in out_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEglsNLnysLU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pick = [i for i in random.sample(range(0, test.shape[0]), 1000)]   # sample random 1000 index from the range of 0 to len(test) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"italic = [test['italian'].values[i] for i in pick]                 # 1000 random italian sentences\n",
        "eng_out = [test['english_out'].values[i] for i in pick]            # 1000 random english sentences\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "italic = [test['italian'].values[i] for i in pick]                 # 1000 random italian sentences\n",
        "\"\"\"italic = [test['italian'].values[i] for i in pick]                 # 1000 random italian sentences\n",
        "eng_out = [test['english_out'].values[i] for i in pick]            # 1000 random english sentences\"\"\"\n",
        "\n",
        "english_out = [test['english_out'].values[i] for i in pick]            # 1000 random english sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_740cNcjLGi"
      },
      "outputs": [],
      "source": [
        "predictions_final = [predict(i) for i in italic]     # predictions on the 1000 italian sentences "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.# https://www.nltk.org/_modules/nltk/translate/bleu_score.html# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences. # https://www.nltk.org/_modules/nltk/translate/bleu_score.html from  nltk.translate.bleu_score import sentence_bleu bleu_list = [] for i in range(len(italic)): bleu_list.append(sentence_bleu(eng_out[i].split(), predictions[i].split())) print(sum(bleu_list)/len(bleu_list))\n",
        "from  nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.# https://www.nltk.org/_modules/nltk/translate/bleu_score.html# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences. # https://www.nltk.org/_modules/nltk/translate/bleu_score.html from  nltk.translate.bleu_score import sentence_bleu bleu_list = [] for i in range(len(italic)): bleu_list.append(sentence_bleu(eng_out[i].split(), predictions[i].split())) print(sum(bleu_list)/len(bleu_list))\n",
        "\n",
        "data_bleu_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(italic)):\n",
        "    data_bleu_list.append(sentence_bleu(english_out[i].split(), predictions_final[i].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996pFO8BLOfG",
        "outputId": "e913da73-79a0-49a4-8d3d-5eb2f391a8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.05582433130462054\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(sum(data_bleu_list)/len(data_bleu_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "    #def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length): super(Encoder, self).__init__() self.inp_vocab_size = inp_vocab_size self.embedding_size = embedding_size self.lstm_size = lstm_size self.input_length = input_length #Initialize Embedding layer self.embedding = tf.keras.layers.Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length) #Intialize Encoder LSTM layer self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_sequences=True, return_state=True) def call(self,input_sequence,states): ''' This function takes a sequence input and the initial states of the encoder. Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm returns -- All encoder_outputs, last time steps hidden and cell state ''' embed_enc = self.embedding(input_sequence) output, state_h, state_c = self.lstm(embed_enc, initial_state=states) return output, state_h, state_c\n",
        "    def __init__(self, input_vocab_size, emb_size, lstm_size, input_length):\n",
        "\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "        self.lstm_size = lstm_size\n",
        "\n",
        "\n",
        "        \"\"\" #Initialize Embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=self.input_vocab_size, output_dim=self.embedding_size, input_length=self.input_length)\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_sequences=True, return_state=True)\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        self.input_length = input_length\n",
        "\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=self.input_vocab_size, \n",
        "                                                    output_dim=self.emb_size, \n",
        "                                                    input_length=self.input_length)\n",
        "        #Intialize Encoder LSTM layer\n",
        "         #Intialize Encoder LSTM layer\n",
        "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, \n",
        "                                            return_sequences=True, \n",
        "                                            return_state=True)\n",
        "'''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "    def call(self, final_input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
        "        '''\n",
        "        final_embed_enc = self.embedding(final_input_sequence)\n",
        "\n",
        "\n",
        "\n",
        "        final_output, final_state_h, final_state_c = self.lstm(final_embed_enc, initial_state=states)\n",
        "\n",
        "\n",
        "        return final_output, final_state_h, final_state_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self, final_batch_size):\n",
        "        '''\n",
        "        Given a batch size it will return intial hidden state and intial cell state.\n",
        "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        '''\n",
        "        return (tf.zeros([final_batch_size, self.lstm_size]), tf.zeros([batchfinal_batch_size_size, self.lstm_size]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRoe65b9LB0D",
        "outputId": "e5d38b37-41db-4d3f-c018-2cdd26539c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size, embedding_size, lstm_size, input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size, input_length, lstm_size) and state_h.shape==(batch_size, lstm_size) and state_c.shape==(batch_size, lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHXr_IwOkXTO"
      },
      "outputs": [],
      "source": [
        "class Attention(tf.keras.layers.Layer):                     # i have added one more argument dec_units which is decoder units to Attention class \n",
        "    '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "    '''#class Attention(tf.keras.layers.Layer): #class One_Step_Decoder(tf.keras.Model): def __init__(self, tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units): # Initialize decoder embedding layer, LSTM and any other objects needed super(One_Step_Decoder, self).__init__() self.attention = Attention(score_fun , att_units, dec_units) self.att_units = att_units self.dec_units = dec_units self.embedding = tf.keras.layers.Embedding(tar_vocab_size, embedding_dim) self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True, return_state=True) self.ws = tf.keras.layers.Dense(tar_vocab_size) def call(self, input_to_decoder, encoder_output, state_h, state_c): ''' One step decoder mechanisim step by step: A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size, 1, embedding_dim) B. Using the encoder_output and decoder hidden state, compute the context vector. C. Concat the context vector with the step A output D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state) E. Pass the decoder output to dense layer(vocab size) and store the result into output. F. Return the states from step D, output from Step E, attention weights from Step -B ''' embed = self.embedding(input_to_decoder)  # embed encoder input context, alignment = self.attention(state_h, encoder_output)    # get context from decoder state and encoder output concat_out = tf.concat([context, tf.squeeze(embed, 1)], 1)           # concat embedding and context concat_out = tf.expand_dims(concat_out,1) lstm_out, state_h, state_c = self.lstm(concat_out)    # pass concated vec to lstm of decoder logits = self.ws(lstm_out) logits = tf.reshape(logits, [logits.shape[0], logits.shape[2]]) return logits, state_h, state_c, alignment, context            # return o/p                    # i have added one more argument dec_units which is decoder units to Attention class ''' Class the calculates score based on the scoring_function using Bahdanu attention mechanism. ''' def __init__(self, scoring_function, att_units, dec_units): super(Attention, self).__init__() self.scoring_function = scoring_function # Please go through the reference notebook and research paper to complete the scoring functions if self.scoring_function=='dot': # Intialize variables needed for Dot score function here pass if scoring_function == 'general': # Intialize variables needed for General score function here self.wa = tf.keras.layers.Dense(dec_units) elif scoring_function == 'concat': # Intialize variables needed for Concat score function here self.W1 = tf.keras.layers.Dense(att_units) self.W2 = tf.keras.layers.Dense(att_units) self.V = tf.keras.layers.Dense(1) def call(self, decoder_hidden_state, encoder_output): ''' Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs. * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output. Multiply the score function with your encoder_outputs to get the context vector. Function returns context vector and attention weights(softmax - scores) ''' if self.scoring_function == 'dot': # Implement Dot score function here decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1) score = tf.matmul(decoder_hidden_state, encoder_output, transpose_b=True) score = tf.transpose(score, [0, 2, 1]) alignment = tf.nn.softmax(score, axis=1) context = tf.matmul(alignment, encoder_output, transpose_a=True) context = tf.reshape(context, [context.shape[0],context.shape[2]]) return context, alignment elif self.scoring_function == 'general': # Implement General score function here decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 2) score = tf.keras.layers.Dot(axes=(2,1))([self.wa(encoder_output), decoder_hidden_state]) alignment = tf.nn.softmax(score, axis=1) context = tf.matmul(alignment, encoder_output, transpose_a=True) context = tf.reshape(context, [context.shape[0],context.shape[2]]) return context, alignment elif self.scoring_function == 'concat': # Implement General score function here decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1) score= self.V(tf.nn.tanh(self.W1(decoder_hidden_state) + self.W2(encoder_output))) alignment = tf.nn.softmax(score, axis=1)                                              # applying softmax layer context = tf.matmul(alignment, encoder_output, transpose_a=True)                      # get context context = tf.reshape(context, [context.shape[0],context.shape[2]]) return context, alignment\n",
        "    def __init__(self, final_scoring_function, attention_units, final_decode_units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.final_scoring_function = final_scoring_function\n",
        "        # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "\n",
        "        if self.final_scoring_function=='dot':\n",
        "\n",
        "        # Intialize variables needed for Dot score function here\n",
        "\n",
        "            pass\n",
        "        if final_scoring_function == 'general':\n",
        "\n",
        "\n",
        "        # Intialize variables needed for General score function here\n",
        "            self.wa = tf.keras.layers.Dense(final_decode_units) \n",
        "\n",
        "            \n",
        "        elif final_scoring_function == 'concat':\n",
        "        # Intialize variables needed for Concat score function here\n",
        "            self.W1 = tf.keras.layers.Dense(attention_units)\n",
        "\n",
        "            self.W2 = tf.keras.layers.Dense(attention_units)\n",
        "\n",
        "\n",
        "\n",
        "            self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, final_decoder_hidden_state, final_encoder_output):\n",
        "        '''\n",
        "        Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "        * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)'''\"\"\"\n",
        "        Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "        * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "        '''\n",
        "        '''\"\"\"\n",
        "        if self.scoring_function == 'dot':\n",
        "            # Implement Dot score function here\n",
        "\n",
        "            final_decoder_hidden_state = tf.expand_dims(final_decoder_hidden_state, 1)\n",
        "\n",
        "\n",
        "            last_score = tf.matmul(final_decoder_hidden_state, \n",
        "                            final_encoder_output, \n",
        "                            transpose_b=True)\n",
        "            score = tf.transpose(last_score, [0, 2, 1])\n",
        "\n",
        "\n",
        "            alignment = tf.nn.softmax(last_score, axis=1)\n",
        "\n",
        "            f_context = tf.matmul(alignment, \n",
        "                                final_encoder_output, \n",
        "                                transpose_a=True)\n",
        "            conf_contextext = tf.reshape(context, \n",
        "                                [context.shape[0],\n",
        "                                f_context.shape[2]])\n",
        "            return f_context, alignment \n",
        "\n",
        "        elif self.final_scoring_function == 'general':\n",
        "            # Implement General score function here\n",
        "            decoder_hidden_state = tf.expand_dims(final_decoder_hidden_state, 2)\n",
        "\n",
        "\n",
        "\n",
        "            last_score = tf.keras.layers.Dot(axes=(2,1))([self.wa(final_encoder_output), \n",
        "                                                        final_decoder_hidden_state])\n",
        "\n",
        "\n",
        "            alignment = tf.nn.softmax(last_score, axis=1)\n",
        "\n",
        "            \"\"\" # Implement General score function here\n",
        "            decoder_hidden_state = tf.expand_dims(final_decoder_hidden_state, 2)\"\"\"\n",
        "            f_context = tf.matmul(alignment, final_encoder_output, transpose_a=True)\n",
        "\n",
        "            f_context = tf.reshape(f_context, [f_context.shape[0],f_context.shape[2]])\n",
        "            return f_context, alignment \n",
        "\n",
        "        elif self.final_scoring_function == 'concat':\n",
        "            # Implement General score function here\n",
        "            decoder_hidden_state = tf.expand_dims(final_decoder_hidden_state, 1)\n",
        "\n",
        "            \n",
        "            last_score= self.V(tf.nn.tanh(self.W1(final_decoder_hidden_state) + self.W2(final_encoder_output)))            \n",
        "            alignment = tf.nn.softmax(last_score, axis=1)                                             \n",
        "            \n",
        "             # applying softmax layer\n",
        "            f_context = tf.matmul(alignment, final_encoder_output, transpose_a=True)                      \n",
        "            \n",
        "            # get context \n",
        "            f_context = tf.reshape(f_context, [f_context.shape[0],f_context.shape[2]])\n",
        "            return f_context, alignment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51x50h_TLrl9",
        "outputId": "0d74292a-f5d3-4b48-adb1-8d6f7a72ad9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_attention(scoring_fun):             \n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size, att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size, input_length, att_units])\n",
        "    attention=Attention(scoring_fun, att_units, att_units)          # i have added extra argument here \n",
        "    context_vector, attention_weights = attention(state_h, encoder_output)\n",
        "    assert(context_vector.shape==(batch_size, att_units) and attention_weights.shape==(batch_size, input_length, 1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))     \n",
        "print(grader_check_attention('general'))   \n",
        "print(grader_check_attention('concat'))    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_nmsMOfir2N"
      },
      "outputs": [],
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self, final_tar_vocab_size, embed_dim, input_length, decode_units ,score_fun ,att_units):\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed#class One_Step_Decoder(tf.keras.Model): def __init__(self, tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units): # Initialize decoder embedding layer, LSTM and any other objects needed super(One_Step_Decoder, self).__init__() self.attention = Attention(score_fun , att_units, dec_units) self.att_units = att_units self.dec_units = dec_units self.embedding = tf.keras.layers.Embedding(tar_vocab_size, embedding_dim) self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True, return_state=True) self.ws = tf.keras.layers.Dense(tar_vocab_size) def call(self, input_to_decoder, encoder_output, state_h, state_c): ''' One step decoder mechanisim step by step: A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size, 1, embedding_dim) B. Using the encoder_output and decoder hidden state, compute the context vector. C. Concat the context vector with the step A output D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state) E. Pass the decoder output to dense layer(vocab size) and store the result into output. F. Return the states from step D, output from Step E, attention weights from Step -B ''' embed = self.embedding(input_to_decoder)  # embed encoder input context, alignment = self.attention(state_h, encoder_output)    # get context from decoder state and encoder output concat_out = tf.concat([context, tf.squeeze(embed, 1)], 1)           # concat embedding and context concat_out = tf.expand_dims(concat_out,1) lstm_out, state_h, state_c = self.lstm(concat_out)    # pass concated vec to lstm of decoder logits = self.ws(lstm_out) logits = tf.reshape(logits, [logits.shape[0], logits.shape[2]]) return logits, state_h, state_c, alignment, context            # return o/p\n",
        "      super(One_Step_Decoder, self).__init__()\n",
        "\n",
        "      self.attention = Attention(score_fun , att_units, dec_units)\n",
        "\n",
        "\n",
        "      self.att_units = att_units\n",
        "\n",
        "\n",
        "      #\"\"\" One step decoder mechanisim step by step: A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size, 1, embedding_dim) B. Using the encoder_output and decoder hidden state, compute the context vector. C. Concat the context vector with the step A output D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state) E. Pass the decoder output to dense layer(vocab size) and store the result into output. F. Return the states from step D, output from Step E, attention weights from Step -B\"\"\"\n",
        "      self.decode_units = decode_units\n",
        "\n",
        "      self.embedding = tf.keras.layers.Embedding(final_tar_vocab_size, embed_dim)\n",
        "\n",
        "      self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True, return_state=True)\n",
        "\n",
        "\n",
        "\n",
        "      self.ws = tf.keras.layers.Dense(final_tar_vocab_size) \n",
        "\n",
        "\n",
        "  def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
        "      '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size, 1, embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "      '''\n",
        "\n",
        "      last_embed = self.embedding(input_to_decoder)  \n",
        "      # embed encoder input\n",
        "      final_context, alignment = self.attention(state_h, encoder_output)    \n",
        "      # get context from decoder state and encoder output\n",
        "      concat_out = tf.concat([final_context, \n",
        "      tf.squeeze(last_embed, 1)], 1)           \n",
        "      \n",
        "      # concat embedding and context\n",
        "      concat_out = tf.expand_dims(concat_out,1)\n",
        "      final_lstm_out, state_h, state_c = self.lstm(concat_out)    \n",
        "      \n",
        "      # pass concated vec to lstm of decoder \n",
        "      logits = self.ws(final_lstm_out)\n",
        "        \"\"\"# pass concated vec to lstm of decoder \n",
        "      logits = self.ws(final_lstm_out)\"\"\"\n",
        "      logits = tf.reshape(logits, \n",
        "                        [logits.shape[0], \n",
        "                        logits.shape[2]])\n",
        "\n",
        "      return logits, state_h, state_c, alignment, final_context            # return o/p "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEXhChnMC1k",
        "outputId": "ae32628a-e748-4970-f699-69fbe87a7597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=One_Step_Decoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size, 1), maxval=10, minval=0, dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size, input_length, dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size, dec_units])    \n",
        "    state_c=tf.random.uniform(shape=[batch_size, dec_units])     \n",
        "    output, state_h, state_c, attention_weights, context_vector = onestepdecoder(input_to_decoder, encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size, tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size, dec_units)) \n",
        "    assert(state_c.shape==(batch_size, dec_units)) \n",
        "    assert(attention_weights.shape==(batch_size, input_length, 1))\n",
        "    assert(context_vector.shape==(batch_size, dec_units))\n",
        "    return True\n",
        "\n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZEgh0_1d8FD"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, final_out_vocab_size, last_embedding_dim, max_input_length, last_dec_units ,score_function , att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoderclass Decoder(tf.keras.Model): def __init__(self, final_out_vocab_size, last_embedding_dim, input_length, last_dec_units ,score_fun , att_units): #Intialize necessary variables and create an object from the class onestepdecoder super(Decoder, self).__init__() self.final_out_vocab_size = final_out_vocab_size self.last_embedding_dim = last_embedding_dim self.input_length = input_length self.last_dec_units = last_dec_units self.score_fun = score_fun self.att_units = att_units self.One_Step_Decoder = One_Step_Decoder(self.final_out_vocab_size, self.last_embedding_dim, self.input_length, self.last_dec_units , self.score_fun, self.att_units) def call(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state ): #Initialize an empty Tensor array, that will store the outputs at each and every time step all_outputs = tf.TensorArray(tf.float32, size=tf.shape(input_to_decoder)[1], name=\"output_arrays\") # #Create a tensor array as shown in the reference notebook #Iterate till the length of the decoder input for timestep in range(tf.shape(input_to_decoder)[1]): # Call onestepdecoder for each token in decoder_input output, decoder_hidden_state, decoder_cell_state, attention_weights, context_vector = self.One_Step_Decoder(input_to_decoder[:,timestep:timestep+1], encoder_output, decoder_hidden_state, decoder_cell_state) # Store the output in tensorarray all_outputs = all_outputs.write(timestep, output) all_outputs = tf.transpose(all_outputs.stack(), [1,0,2]) # Return the tensor array return all_outputs def initialize_states(self, batch_size): ''' Given a batch size it will return intial hidden state and intial cell state. If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units] ''' return (tf.zeros([batch_size, self.dec_units]), tf.zeros([batch_size, self.dec_units]))\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.final_out_vocab_size = final_out_vocab_size\n",
        "\n",
        "        self.last_embedding_dim = last_embedding_dim\n",
        "\n",
        "        self.max_input_length = max_input_length \n",
        "\n",
        "        self.last_dec_units = last_dec_units\n",
        "\n",
        "        self.score_function = score_function\n",
        "\n",
        "        self.att_units = att_units  \n",
        "\n",
        "        self.One_Step_Decoder = One_Step_Decoder(self.final_out_vocab_size, self.last_embedding_dim, self.max_input_length, self.last_dec_units , self.score_function, self.att_units)\n",
        "\n",
        "    def call(self, final_input_to_decoder, last_encoder_output, final_decoder_hidden_state, decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        all_outputs = tf.TensorArray(tf.float32, size=tf.shape(final_input_to_decoder)[1], name=\"output_arrays\") #\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        \n",
        "        #Iterate till the length of the decoder input\n",
        "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            output, decoder_hidden_state, decoder_cell_state, attention_weights, context_vector = self.One_Step_Decoder(\n",
        "                                                                                final_input_to_decoder[:,timestep:timestep+1], \n",
        "                                                                                last_encoder_output, \n",
        "                                                                                final_decoder_hidden_state, \n",
        "                                                                                decoder_cell_state) \n",
        "            # Store the output in tensorarray\n",
        "            all_outputs = all_outputs.write(timestep, output)\n",
        "\n",
        "        all_outputs = tf.transpose(all_outputs.stack(), [1,0,2])\n",
        "        # Return the tensor array\n",
        "        return all_outputs\n",
        "\n",
        "    def initialize_states(self, max_batch_size):\n",
        "        '''\n",
        "        Given a batch size it will return intial hidden state and intial cell state.\n",
        "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        ''''''\n",
        "        Given a batch size it will return intial hidden state and intial cell state.\n",
        "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        '''\n",
        "        return (tf.zeros([max_batch_size, self.dec_units]), tf.zeros([max_batch_size, self.dec_units]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtbx6onFMJXb",
        "outputId": "5e267f0c-f537-4bae-af41-39ef681b74e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size, input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output = tf.random.uniform(shape=[batch_size, input_length, dec_units])                  \n",
        "    state_h=tf.random.uniform(shape=[batch_size, dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size, dec_units])\n",
        "    \n",
        "    decoder = Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output = decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size, input_length, out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2UCvjFBjT8w"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):         # passing decoder init state to deoder and not encoder init state\n",
        "  def __init__(self, final_vocab_size_en, max_embedding_size_en, max_lstm_size_en, final_input_length_en, last_batch_size,\n",
        "               last_out_vocab_size_de, embedding_dim_de, input_length_de, dec_units ,score_fun ,att_units):\n",
        "      \"\"\"super(encoder_decoder, self).__init__()      \n",
        "      #Intialize objects from encoder\n",
        "      self.vocab_size_en = vocab_size_en\n",
        "      self.embedding_size_en = embedding_size_en\n",
        "      self.lstm_size_en = lstm_size_en\n",
        "      self.input_length_en = input_length_en\n",
        "      self.batch_size = batch_size\n",
        "      self.encoder = Encoder(self.vocab_size_en, self.embedding_size_en, self.lstm_size_en, self.input_length_en)  # Encoder\n",
        "      self.initial_state = self.encoder.initialize_states(self.batch_size)\"\"\"\n",
        "\n",
        "\n",
        "      super(encoder_decoder, self).__init__()  \n",
        "\n",
        "      \n",
        "      #Intialize objects from encoder\n",
        "      #Intialize objects from encoder\n",
        "      self.final_vocab_size_en = final_vocab_size_en\n",
        "\n",
        "      self.max_embedding_size_en = max_embedding_size_en\n",
        "\n",
        "      self.max_lstm_size_en = max_lstm_size_en\n",
        "\n",
        "\n",
        "\n",
        "      self.final_input_length_en = final_input_length_en\n",
        "\n",
        "      self.last_batch_size = last_batch_size\n",
        "      self.encoder = Encoder(self.final_vocab_size_en, \n",
        "                              self.max_embedding_size_en, \n",
        "                              self.max_lstm_size_en, \n",
        "                              self.final_input_length_en)  \n",
        "      \n",
        "      # Encoder\n",
        "      self.initial_state = self.encoder.initialize_states(self.last_batch_size)\n",
        "      \n",
        "      #Intialize objects from decoder\n",
        "      self.last_out_vocab_size_de = last_out_vocab_size_de \n",
        "\n",
        "\n",
        "      self.embedding_dim_de = embedding_dim_de \n",
        "      \"\"\"self.input_length_de = input_length_de\n",
        "      self.dec_units = dec_units \n",
        "      self.att_units = att_units\"\"\"\n",
        "      \n",
        "      self.input_length_de = input_length_de\n",
        "      self.dec_units = dec_units \n",
        "      self.att_units = att_units\n",
        "\n",
        "\n",
        "      self.score_fun = score_fun\n",
        "      self.decoder = Decoder(self.last_out_vocab_size_de, \n",
        "                              self.embedding_dim_de, \n",
        "                              self.input_length_de, \n",
        "                              self.dec_units, \n",
        "                              self.score_fun, \n",
        "                              self.att_units)  \n",
        "      \n",
        "      # Decoder\n",
        "      self.initial_state_decoder = self.decoder.initialize_states(self.batch_size)\n",
        "\n",
        "  def call(self, df_data):\n",
        "    input_sequence, target_sentences = df_data[0], df_data[1]\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    encoder_output, state_h, state_c = self.encoder(input_sequence, self.initial_state)\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output, decoder states to Decoder\n",
        "    final_decoder_output = self.decoder(target_sentences, encoder_output, self.initial_state_decoder[0], self.initial_state_decoder[1])   # get the output of the decoder \n",
        "    # return the decoder output\n",
        "    return final_decoder_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G87qJ7U-Lm6T"
      },
      "source": [
        "<font color='blue'>**Training with dot scoring function**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgyWwZWeMxGQ"
      },
      "outputs": [],
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input, decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita, train_eng], train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input, decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "max_vocab_size_en = vocabularry_size_ita+1\n",
        "\n",
        "max_embedding_size_en = 50\n",
        "\n",
        "best_lstm_size_en = 128\n",
        "\n",
        "max_input_length_en = 20\n",
        "\n",
        "max_batch_size = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_out_vocab_size_de = vocabularry_size_eng+1 \n",
        "\n",
        "\n",
        "final_embedding_dim_de = 50\n",
        "\n",
        "max_input_length_de = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4pQOHUjk0tK"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "dec_units = 128\n",
        "value_of_score_fun = 'dot'\n",
        "att_units = 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#encoder_decoder_model = encoder_decoder(max_vocab_size_en, max_embedding_size_en, best_lstm_size_en, max_input_length_en, batch_size, final_out_vocab_size_de, final_embedding_dim_de, max_input_length_de, dec_units , value_of_score_fun , att_units)\n",
        "\n",
        "\n",
        "encoder_decoder_model = encoder_decoder(max_vocab_size_en, \n",
        "                                        max_embedding_size_en, \n",
        "                                        best_lstm_size_en, \n",
        "                                        max_input_length_en, \n",
        "                                        batch_size,\n",
        "                                        final_out_vocab_size_de, \n",
        "                                        final_embedding_dim_de, \n",
        "                                        max_input_length_de, \n",
        "                                        dec_units ,\n",
        "                                        value_of_score_fun ,\n",
        "                                        att_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI8Du4jLpfdE"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#encoder_decoder_model = encoder_decoder(max_vocab_size_en, max_embedding_size_en, best_lstm_size_en, max_input_length_en, batch_size, final_out_vocab_size_de, final_embedding_dim_de, max_input_length_de, dec_units , value_of_score_fun , att_units)\n",
        "\n",
        "\n",
        "encoder_decoder_model.compile(optimizer=optimizer, loss=loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_train_steps = train_data.shape[0]//1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_test_steps = test_data.shape[0]//1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3g5EXrawa_h",
        "outputId": "c6b54511-c866-4dba-9575-d839c937a747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "273/273 [==============================] - 92s 323ms/step - loss: 1.9930 - val_loss: 1.7389\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 88s 323ms/step - loss: 1.6406 - val_loss: 1.5277\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 88s 320ms/step - loss: 1.4397 - val_loss: 1.3646\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 98s 359ms/step - loss: 1.3125 - val_loss: 1.2563\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 88s 322ms/step - loss: 1.2162 - val_loss: 1.1594\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 98s 359ms/step - loss: 1.1237 - val_loss: 1.0704\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 99s 361ms/step - loss: 1.0396 - val_loss: 0.9900\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 88s 321ms/step - loss: 0.9603 - val_loss: 0.9128\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 88s 323ms/step - loss: 0.8847 - val_loss: 0.8360\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 99s 361ms/step - loss: 0.8091 - val_loss: 0.7597\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 88s 322ms/step - loss: 0.7349 - val_loss: 0.6898\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 87s 320ms/step - loss: 0.6649 - val_loss: 0.6211\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 97s 357ms/step - loss: 0.6010 - val_loss: 0.5595\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 88s 321ms/step - loss: 0.5447 - val_loss: 0.5085\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 87s 319ms/step - loss: 0.4957 - val_loss: 0.4615\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 87s 319ms/step - loss: 0.4513 - val_loss: 0.4213\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 97s 357ms/step - loss: 0.4141 - val_loss: 0.3868\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 87s 320ms/step - loss: 0.3818 - val_loss: 0.3574\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.3571 - val_loss: 0.3300\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 98s 358ms/step - loss: 0.3300 - val_loss: 0.3101\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 88s 321ms/step - loss: 0.3073 - val_loss: 0.2866\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 87s 320ms/step - loss: 0.2881 - val_loss: 0.2674\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.2716 - val_loss: 0.2536\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 97s 357ms/step - loss: 0.2563 - val_loss: 0.2388\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 87s 319ms/step - loss: 0.2432 - val_loss: 0.2304\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 86s 316ms/step - loss: 0.2311 - val_loss: 0.2178\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 87s 319ms/step - loss: 0.2214 - val_loss: 0.2101\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.2111 - val_loss: 0.2000\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.2010 - val_loss: 0.1891\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 86s 316ms/step - loss: 0.1928 - val_loss: 0.1821\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1895 - val_loss: 0.1769\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 86s 316ms/step - loss: 0.1808 - val_loss: 0.1697\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 87s 319ms/step - loss: 0.1732 - val_loss: 0.1623\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 87s 319ms/step - loss: 0.1682 - val_loss: 0.1604\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.1672 - val_loss: 0.1582\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.1612 - val_loss: 0.1531\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 87s 320ms/step - loss: 0.1540 - val_loss: 0.1439\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1500 - val_loss: 0.1409\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1448 - val_loss: 0.1362\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1413 - val_loss: 0.1342\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 86s 316ms/step - loss: 0.1376 - val_loss: 0.1282\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.1348 - val_loss: 0.1302\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1326 - val_loss: 0.1227\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1283 - val_loss: 0.1194\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 87s 318ms/step - loss: 0.1245 - val_loss: 0.1168\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 86s 317ms/step - loss: 0.1225 - val_loss: 0.1167\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.1198 - val_loss: 0.1133\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.1171 - val_loss: 0.1099\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 87s 317ms/step - loss: 0.1148 - val_loss: 0.1068\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 86s 315ms/step - loss: 0.1163 - val_loss: 0.1061\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe5e2bf6150>"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"encoder_decoder_model.fit(train_dataloader, \n",
        "                            steps_per_epoch=total_train_steps, \n",
        "                            epochs=50, \"\"\"\n",
        "\n",
        "\n",
        "encoder_decoder_model.fit(train_dataloader, \n",
        "                            steps_per_epoch=total_train_steps, \n",
        "                            epochs=50, \n",
        "                            validation_data=train_dataloader, \n",
        "                            validation_steps=total_test_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyzUJvkQ4SUR"
      },
      "outputs": [],
      "source": [
        "def plot_attention(attestion_data, final_italic_sentence, best_prediction):   # given attention matrix/list of lists italic sentence and prediction from encoder_decoder model get the plot \n",
        "    #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate# given attention matrix/list of lists italic sentence and prediction from encoder_decoder model get the plot #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "    final_new_att = []  \n",
        "    \n",
        "     # getting attention weights \n",
        "    for i in range(len(attestion_data)):\n",
        "        at = [i[0] for i in att[i].numpy()[0]] \n",
        "        final_new_att.append(at)\n",
        "        \n",
        "    final_fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    axis_last = final_fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    axis_last.matshow(final_new_att)         \n",
        "    # ploting  # given attention matrix/list of lists italic sentence and prediction from encoder_decoder model get the plot #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "    axis_last.set_xticklabels([''] + final_italic_sentence.split(' '), rotation=90)\n",
        "    axis_last.set_yticklabels([''] + best_prediction)\n",
        "\n",
        "\n",
        "    plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP3kLZoPMvSu"
      },
      "outputs": [],
      "source": [
        "def predict(final_input_sentence):##''' A. Given input sentence, convert the sentence into integers using tokenizer used earlier B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder. D. till we reach max_length of decoder or till the model predicted word <end>: predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states) Save the attention weights And get the word using the tokenizer(word index) and then store it in a string. E. Call plot_attention(#params) F. Return the predicted sentence '''\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "\n",
        "    best_test_source_seq = tknizer_ita.texts_to_sequences([final_input_sentence])\n",
        "\n",
        "    if len(best_test_source_seq[0]) == 0:\n",
        "        return \"not a italic word\"\n",
        "\n",
        "    encoder = encoder_decoder_model.layers[0]\n",
        "    \n",
        "    english_initial_states = encoder.initialize_states(1)\n",
        "\n",
        "    decoder_init = encoder_decoder_model.layers[1].initialize_states(1)\n",
        "\n",
        "    encoder_output, state_h, state_c = encoder(tf.constant(best_test_source_seq), \n",
        "                                                english_initial_states)\n",
        "\n",
        "    decoder_input = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
        "\n",
        "    save_attention = []\n",
        "\n",
        "    out_words = []\n",
        "\n",
        "    while True:\n",
        "        predictions, state_h, state_c, attention_weights, context_vector = encoder_decoder_model.layers[1].layers[0](de_input, \n",
        "                                                                                                                        encoder_output, \n",
        "                                                                                                                        decoder_init[0], \n",
        "                                                                                                                        decoder_init[1])\n",
        "        save_attention.append(attention_weights)\n",
        "\n",
        "        decoder_input = tf.argmax(predictions, -1)\n",
        "    \n",
        "        if decoder_input.numpy()[0] == 0:\n",
        "            out_words.append('')       \n",
        "        \n",
        "        else:\n",
        "            out_words.append(tknizer_eng.index_word[decoder_input.numpy()[0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:#or out_words[0] == out_words[-1]:\n",
        "            break\n",
        "            \n",
        "        decoder_input = tf.constant([[decoder_input.numpy()[0]]])\n",
        "\n",
        "    plot_attention(save_attention, input_sentence, out_words)\n",
        "    \n",
        "    return ' '.join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVKTsNJJ567Q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "pick = [i for i in random.sample(range(0, test.shape[0]), 1000)]\n",
        "italic = [test['italian'].values[i] for i in pick]\n",
        "eng_out = [test['english_out'].values[i] for i in pick]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "g-Yj9GRpZ-bS",
        "outputId": "1c129893-e4d2-4625-d966-bf49b83c044e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dna test is it is it is it is it is it is it is it is it is it'"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(italic[405])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "nBqGH_Opf0or",
        "outputId": "68516b69-7ca9-42c1-d0da-760e43b957a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKMAAAJoCAYAAAAK3FHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASyklEQVR4nO3dedBddX3H8c+HLTHBAEFkGSxYBRnQLBBB2WTtMGOBQUCwogKOqX+IBYfamS5Tl6FTUYdRqW2DQJ0OUqAtraatUIK2gcoeQli02AJV2RSEsEiA8O0f5zzmknkgD3nOvffzPPf9msnkbs/5/W54c86599x7HleVgASbDHsCwBhiRAxiRAxiRAxiRAxiRAxiRAxiRAxiRIzNhj0BTC22t5P0B5L2lDRz7PaqOmyyy2bNiNfqEkn3SHqzpM9Kul/SzV0s2BybxkTY/rikZySdWVX72L6jqua1991cVe+c7BisGbFBts+QtElV/a2kF9qbH7L9XtsLJc3tZBzWjNgQ25tX1Qvt5d+WtFzSmyR9TdIcSZ+tqm9PdhxewGCDekLcVNJuVbVU0pOSDu1ynJHZTNt+l+2bbT9t+3nba22vHva8ppKqWivpA/1a/iitGc+XdLKkKyQtkvRhSbsPdUZT0/W2z5d0mZoXNJKkqrptsgsemX1G27dU1aL1XgWuqKqFw57bVGL7e+PcXF28zzhKa8ZnbW8h6Xbb50p6SCO0m9KVqup0P7HXKP3H+JCa5/sJNZuXN0k6fqgzmoJsb2/7Qtv/1l7f0/ZHO1n2CG2mZ0v6VVW91F7fVNKMqnp2uDObWtoIL5b0R1U13/ZmklZU1Tsmu+xRWjMukzSr5/rrJF0zpLlMZW+oqsslvSRJVfWipLVdLHiUYpxZVU+PXWkvz3qVx2N8z9jeVlJJzVtmat5znLRRegHzjO29x96CsL2PpF8NeU5T0ackfVvSW2xfL2k7SSd0seBRivFMSVfYflCSJe0g6aThTmlqafez39P+eZuaf8cfjR2hmfTyR+UFjNQcY1Xzjyh1+I84SmzfVFX79mXZ0z1G24dV1bW23zfe/VX1j4Oe01Rm+zxJm6sPR2BGYTN9sKRrJR09zn0liRhfmwXt35/rua0kcQRmAn7Z/n1hVV031JlMAxyBmZzT2r+/OtRZTBO2t7X9Vdu32b7V9lfat3ombRTWjPfYvlfSTrbv6Lndag7wzxvSvKaqv5P0n1p3KPWDavYfj5jsgqf9CxhJsr2DpKskHbP+fVX1wOBnNHXZvrOq3r7ebau6OBw4CmtGVdXDkuYPex7TxNW2T5Z0eXv9BDX/o0/atF8z2r68qt5ve5XaQ1hjd4nN9Gtm+ylJs9Uem1bzumPsLZ6qqjkbvewRiHHHqnrI9i7j3c9mOse0jxHdsz1P0q7q2c3r4uDBSOwzSlJ7BOYLkt6oZhM9tpne6M3KKLJ9kaR5ku7Suk11JwcPRmbNaPvHko6uqnuGPZepzPbdVbVnP5Y9Cm96j3lkkCHaPtD2ae3l7Wy/eVBj99kPbPclxlFaM35FzcfG/knSmrHb+/FBCdt/qubrsG+rqt1t7yTpiqo6oOuxBs32e9R8nvFhNf+Onb0rMTL7jGpOw/GspN/qua1fH5Q4TtJCSbdJUlU9aPv1fRhnGC5U8+W2VVq3z9iJkYmxqk7b8KM683xVle2xj+bPHuDY/fbzLs6rM56RidH2eB+UeFLSLVX1zx0Pd7ntv5a0te2PSTpd0gUdjzEsK2x/S9J31PHuzijtMy6RtIea05tIzYH++yRtK+l/q+rMjsc7Us0ugSVdVVX/3uXyh8X2xePcXFV1+qSXPUIx3iDpgPbkRWq/77tc0oGSVvXr7QpM3Ci9tbONpC17rs+WNLeNc834P7JxbL/P9r22n7S92vZT0+WMZ7Z3tn2l7UfbP/9ge+culj0y+4ySzlVznp3vq9l0Hizpz9oXF11/mf9cTd832C+W9C1JJ7bXT2lvO3KyCx6ZzbTUfGhC0tg3226uqgf7NM71w3hP0fYb9fLfQPB/fRjj9qpasKHbNsa0XzPa3qOqfmh77/amn7R/72B7hy6+1dYz1tg3EG+xfZkG8AZ7O+4xkr4saSdJj0raRc1vJNirD8M9ZvsUSZe21z8g6bEuFjzt14y2l1TV4vXOK/jrJ93FeQV7xhp7pVlqdgV6dfKK8xXGXanm23nXVNVC24dKOqWqOjk72Hpj7aLmXN7vVvM8/0vSGVX1k1f9wYmoqpH4I+n9kua0l/9E0pWS9u7TWN+UtHXP9W0kXdTH53ZL+/dKNb+VQJJW9vG5bdNzfW5Xz22UXk3/cVWttn2gmrXINyT9ZZ/GmldVT4xdqapfqjk82C9P2N5SzRelLmmPwz+zgZ/ZWPPa5yNJqqrH1dFzG6UYx07b9l5JF1TVv0jaok9jbWJ7m7Ertueqv/vnx6o5idVZkr4r6X80/kkLutC35zbtX8D0+Fl7iO5ISV+wPUP9+5/xy2o+ajV2tOdESef0aSxVVe9a8Jv9GqfVt+c27V/AjLE9S9JRao623Nu+zfOOqrq6T+PtqXWn/Li2qu7uwxhP6eVfMvv1Xerjp9j79dxGJkbkG6V9RoQjRsQYyRhtL56OYw16vK7HGskYJQ0ykIHGOODxiBHT05R/Nb2FZ9RMvbavmLygNdpcM/o0o+GNNejxNmas5/SMnq816x+3lzQN3vSeqdnaz4cPexqYoBtr2Svex2YaMYgRMYgRMYgRMYgRMYgRMYgRMQYSo+2nN/yolz3+ENv792s+yJS6ZjxEEjGOmE5itP37tj/ZXj7P9rXt5cNsX9JePsf2Sts32N6+ve1o2zfaXmH7Gtvb295V0sclnWX7dtsHdTFH5Otqzbhc0lg0iyRt2f5u54PUfGNttqQbqmp+e/1j7WOvk/Suqlqo5teAfbqq7pf0V5LOq6oFVbW8ozkiXFfHpm+VtI/tOWrOoHCbmigPkvRJSc9LWtrz2LHzsuws6bL2+yhbqDlF3Qa1n6NbLEkzNaujp4Bh62TNWM1vtL9P0qlqzjCwXNKhkt6q5jQbL9S6jwet1br/Cb4m6fxqfu/c76rnPDEbGG9JVS2qqkWD/EQM+qvLFzDLJZ2tZjO8XM1+34p69c+obSXpZ+3lj/Tc/pSk6XIObExQ1zHuKOkHVfWIpOfa217NZyRdYftWSb/ouf07ko7jBcxomfIfrp3jucXnGaeOG2uZVtfj4364NvV9RowgYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkQMYkSMocRoe1fbdw5jbORizYgYw4xxU9sX2L7L9tW2X2f7Lba/a/tW28tt7zHE+WHAhhnjbpL+oqr2kvSEpOMlLZF0RlXtI+lsSV8f4vwwYJsNcez7qur29vKtknaVtL+kK2yPPWbGeD9oe7GkxZI0U7P6O0sMzDBjXNNzea2k7SU9UVULNvSDVbVEzVpUczy3+jM9DFrSC5jVku6zfaIkuTF/yHPCACXFKEkflPRR2ysl3SXp2CHPBwM0lM10Vd0v6e0917/Uc/dRA58QIqStGTHCiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExiBExNhij7V1t/9D239j+b9uX2D7C9vW277W9r+3Zti+yfZPtFbaP7fnZ5bZva//s395+iO3v2/77dtmX2HZ735/bvtv2Hba/1N+njySbTfBxb5V0oqTTJd0s6XckHSjpGEl/KOluSddW1em2t5Z0k+1rJD0q6ciqes72bpIulbSoXeZCSXtJelDS9ZIOsH2PpOMk7VFV1S4LI2KiMd5XVaskyfZdkpa1sayStKuknSUdY/vs9vEzJf2GmtDOt71A0lpJu/cs86aq+mm7zNvb5dwg6TlJF9peKmnpeJOxvVjS4magWRN8Ckg30RjX9Fx+qef6S+0y1ko6vqp+1PtDtj8j6RFJ89XsEjz3CstcK2mzqnrR9r6SDpd0gqRPSDps/clU1RJJSyRpjufWBJ8DwnX1AuYqSWf07PctbG/fStJDVfWSpA9J2vTVFmJ7S0lbVdW/SjpLTcQYEV3F+HlJm0u6o92Mf769/euSPmJ7paQ9JD2zgeW8XtJS23dIuk7SpzqaH6YAV03trdwcz639fPiwp4EJurGWaXU97vHu431GxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxCBGxOhrjLY/Z/vMnuvn2P4921+0faftVbZPau87xPbSnseeb/vUfs4PWfq9ZrxI0oclyfYmkk6W9FNJCyTNl3SEpC/a3rHP88AUsFk/F15V99t+zPZCSdtLWiHpQEmXVtVaSY/Y/g9J75S0eqLLtb1Y0mJJmqlZ3U8cQzGIfcZvSDpV0mlq1pSv5MX15jPzlR5YVUuqalFVLdpcMzqZJIZvEDFeKekoNWu/qyQtl3SS7U1tbyfpYEk3SXpA0p62Z9jeWtLhA5gbgvR1My1JVfW87e9JeqKq1tq+UtK7Ja2UVJI+XVUPS5LtyyXdKek+NZt0jBBXVX8HaF643CbpxKq6t+vlz/Hc2s+sRKeKG2uZVtfjHu++fr+1s6ekH0ta1o8QMb30+9X03ZJ+s59jYPrgCAxiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiECNiuKqGPYdJsf1zSQ+8xh97g6Rf9GE6wx5r0ONtzFi7VNV2490x5WPcGLZvqapF022sQY/X9VhsphGDGBFjVGNcMk3HGvR4nY41kvuMyDSqa0YEIkbEIEbEIEbEIEbE+H8m0LXxeJf2eAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'what he means you want that mean tom how you want that mean tom how you want that mean tom'"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(italic[80])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdlEyOnF6X9k"
      },
      "outputs": [],
      "source": [
        "# encoder_decoder_model.save_weights('attention_model.h5')\n",
        "# encoder_decoder_model.load_weights('attention_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_ZKzW-RJNNq"
      },
      "outputs": [],
      "source": [
        "def predict_eng(input_sentence):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "\n",
        "    test_source_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    if len(test_source_seq[0]) == 0:\n",
        "        return \"not a italic word\"\n",
        "    encoder = encoder_decoder_model.layers[0]\n",
        "    \n",
        "    en_initial_states = encoder.initialize_states(1)\n",
        "    \n",
        "    decoder_init = encoder_decoder_model.layers[1].initialize_states(1)\n",
        "\n",
        "    encoder_output, state_h, state_c = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
        "\n",
        "    save_attention = []   # add attention weights for each each decoding step \n",
        "    out_words = []\n",
        "    while True:\n",
        "        predictions, state_h, state_c, attention_weights, context_vector = encoder_decoder_model.layers[1].layers[0](de_input, encoder_output, decoder_init[0], decoder_init[1])\n",
        "        save_attention.append(attention_weights)\n",
        "\n",
        "        de_input = tf.argmax(predictions, -1)\n",
        "    \n",
        "        if de_input.numpy()[0] == 0:\n",
        "            out_words.append(' ')       \n",
        "        \n",
        "        else:\n",
        "            out_words.append(tknizer_eng.index_word[de_input.numpy()[0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:#or out_words[0] == out_words[-1]:\n",
        "            break\n",
        "            \n",
        "        de_input = tf.constant([[de_input.numpy()[0]]])\n",
        "\n",
        "    return ' '.join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8vctiMIJ7sC"
      },
      "outputs": [],
      "source": [
        "predictions = [predict_eng(i) for i in italic]  # prediction for random 1000 text data points   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmvEAYUVJNax",
        "outputId": "edd2080e-f47b-4d67-f82c-78d417344ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1519385873664515\n"
          ]
        }
      ],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from  nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_list = []\n",
        "for i in range(len(predictions)):\n",
        "    bleu_list.append(sentence_bleu(eng_out[i].split(), predictions[i].split()))\n",
        "\n",
        "print(sum(bleu_list)/len(bleu_list))   #bleu score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scyY4wlzKUCq"
      },
      "source": [
        "## Model-2 with \"general\" Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSTomjwgLfst"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFa-JMKHgeQD"
      },
      "outputs": [],
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "\n",
        "vocab_size_en = vocab_size_ita+1\n",
        "embedding_size_en = 50\n",
        "lstm_size_en = 128\n",
        "input_length_en = 256\n",
        "batch_size = 1024\n",
        "out_vocab_size_de = vocab_size_eng+1 \n",
        "embedding_dim_de = 50\n",
        "input_length_de = 20\n",
        "dec_units = 512\n",
        "score_fun = 'general'  # dot function  \n",
        "att_units = 1024\n",
        "\n",
        "encoder_decoder_model_general = encoder_decoder(vocab_size_en, embedding_size_en, lstm_size_en, input_length_en, batch_size,\n",
        "                                        out_vocab_size_de, embedding_dim_de, input_length_de, dec_units ,score_fun ,att_units)        # initializing encoder_decoder model with 'dot' score function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrNjNQulgpzy"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "encoder_decoder_model_general.compile(optimizer=optimizer, loss=loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbUaAqSWgp-5",
        "outputId": "fb2f1c3b-112e-44b1-eb98-f456fe77c994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "273/273 [==============================] - 165s 590ms/step - loss: 1.8873 - val_loss: 1.6370\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 160s 585ms/step - loss: 1.5135 - val_loss: 1.4210\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 160s 587ms/step - loss: 1.3729 - val_loss: 1.3117\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 161s 588ms/step - loss: 1.2783 - val_loss: 1.2336\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 166s 609ms/step - loss: 1.2112 - val_loss: 1.1741\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 161s 590ms/step - loss: 1.1478 - val_loss: 1.1039\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 161s 590ms/step - loss: 1.0799 - val_loss: 1.0355\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 166s 609ms/step - loss: 1.0139 - val_loss: 0.9752\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 161s 589ms/step - loss: 0.9531 - val_loss: 0.9143\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 161s 589ms/step - loss: 0.8949 - val_loss: 0.8565\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 161s 589ms/step - loss: 0.8396 - val_loss: 0.8025\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 166s 609ms/step - loss: 0.7864 - val_loss: 0.7506\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 161s 591ms/step - loss: 0.7380 - val_loss: 0.7019\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.6933 - val_loss: 0.6585\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 166s 608ms/step - loss: 0.6510 - val_loss: 0.6169\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 166s 608ms/step - loss: 0.6099 - val_loss: 0.5769\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 166s 610ms/step - loss: 0.5718 - val_loss: 0.5400\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.5348 - val_loss: 0.5047\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.5009 - val_loss: 0.4742\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.4709 - val_loss: 0.4438\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 167s 610ms/step - loss: 0.4428 - val_loss: 0.4185\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 162s 592ms/step - loss: 0.4180 - val_loss: 0.3928\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 167s 610ms/step - loss: 0.3934 - val_loss: 0.3705\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 162s 592ms/step - loss: 0.3719 - val_loss: 0.3489\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 161s 591ms/step - loss: 0.3525 - val_loss: 0.3295\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 161s 591ms/step - loss: 0.3334 - val_loss: 0.3125\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 161s 589ms/step - loss: 0.3163 - val_loss: 0.2983\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 161s 591ms/step - loss: 0.3020 - val_loss: 0.2852\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 161s 590ms/step - loss: 0.2870 - val_loss: 0.2692\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.2730 - val_loss: 0.2547\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.2597 - val_loss: 0.2433\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 161s 590ms/step - loss: 0.2484 - val_loss: 0.2317\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.2372 - val_loss: 0.2214\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 167s 611ms/step - loss: 0.2275 - val_loss: 0.2129\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 161s 590ms/step - loss: 0.2182 - val_loss: 0.2027\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 166s 609ms/step - loss: 0.2088 - val_loss: 0.1941\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 161s 591ms/step - loss: 0.1998 - val_loss: 0.1870\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 161s 591ms/step - loss: 0.1921 - val_loss: 0.1794\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 167s 610ms/step - loss: 0.1849 - val_loss: 0.1722\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 166s 609ms/step - loss: 0.1779 - val_loss: 0.1649\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 167s 610ms/step - loss: 0.1716 - val_loss: 0.1599\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 161s 588ms/step - loss: 0.1663 - val_loss: 0.1553\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 161s 588ms/step - loss: 0.1599 - val_loss: 0.1507\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 161s 589ms/step - loss: 0.1550 - val_loss: 0.1429\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 166s 610ms/step - loss: 0.1492 - val_loss: 0.1383\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 161s 590ms/step - loss: 0.1444 - val_loss: 0.1341\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 161s 589ms/step - loss: 0.1402 - val_loss: 0.1299\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 166s 609ms/step - loss: 0.1360 - val_loss: 0.1255\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 161s 588ms/step - loss: 0.1315 - val_loss: 0.1213\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 161s 588ms/step - loss: 0.1276 - val_loss: 0.1223\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe43d34acd0>"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_steps = train.shape[0]//1024      \n",
        "test_steps = test.shape[0]//1024         \n",
        "\n",
        "encoder_decoder_model_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=train_dataloader, validation_steps=test_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9rzk1IEAU3v"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "\n",
        "    test_source_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    if len(test_source_seq[0]) == 0:\n",
        "        return \"not a italic word\"\n",
        "    encoder = encoder_decoder_model_general.layers[0]\n",
        "    \n",
        "    en_initial_states = encoder.initialize_states(1)\n",
        "\n",
        "    decoder_init = encoder_decoder_model_general.layers[1].initialize_states(1)\n",
        "\n",
        "    encoder_output, state_h, state_c = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
        "\n",
        "    save_attention = []\n",
        "    out_words = []\n",
        "    while True:\n",
        "        predictions, state_h, state_c, attention_weights, context_vector = encoder_decoder_model_general.layers[1].layers[0](de_input, encoder_output, decoder_init[0], decoder_init[1])\n",
        "        save_attention.append(attention_weights)\n",
        "\n",
        "        de_input = tf.argmax(predictions, -1)\n",
        "    \n",
        "        if de_input.numpy()[0] == 0:\n",
        "            out_words.append('')       \n",
        "        \n",
        "        else:\n",
        "            out_words.append(tknizer_eng.index_word[de_input.numpy()[0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:#or out_words[0] == out_words[-1]:\n",
        "            break\n",
        "            \n",
        "        de_input = tf.constant([[de_input.numpy()[0]]])\n",
        "\n",
        "    plot_attention(save_attention, input_sentence, out_words)\n",
        "    \n",
        "    return ' '.join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "3vK0EGcWAEdw",
        "outputId": "39e39180-5a73-4fe9-f72c-63d10fb285b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i love stop they hated ask stop they hated ask stop they hated ask stop they hated ask stop they'"
            ]
          },
          "execution_count": 40,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualize few sentences randomly in Test data\n",
        "\n",
        "predict(italic[400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "FQrUnDHDAKez",
        "outputId": "d672296a-eab2-4a71-e916-2bca776559e4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i love stop click explaining sorry assistance i love stop click explaining sorry assistance i love stop click explaining sorry'"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(italic[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "cIN2osOvAjf-",
        "outputId": "92b27360-09e0-4fc3-f1c2-63588d006e3b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i love pairs juice assistance i love pairs juice assistance i love pairs juice assistance i love pairs juice assistance'"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(italic[896])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK9pDEAZBQkh"
      },
      "outputs": [],
      "source": [
        "def predict_eng(input_sentence):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "\n",
        "    test_source_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    if len(test_source_seq[0]) == 0:\n",
        "        return \"not a italic word\"\n",
        "    encoder = encoder_decoder_model_general.layers[0]\n",
        "    \n",
        "    en_initial_states = encoder.initialize_states(1)\n",
        "    \n",
        "    decoder_init = encoder_decoder_model_general.layers[1].initialize_states(1)\n",
        "\n",
        "    encoder_output, state_h, state_c = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
        "\n",
        "    save_attention = []   # add attention weights for each each decoding step \n",
        "    out_words = []\n",
        "    while True:\n",
        "        predictions, state_h, state_c, attention_weights, context_vector = encoder_decoder_model_general.layers[1].layers[0](de_input, encoder_output, decoder_init[0], decoder_init[1])\n",
        "        save_attention.append(attention_weights)\n",
        "\n",
        "        de_input = tf.argmax(predictions, -1)\n",
        "    \n",
        "        if de_input.numpy()[0] == 0:\n",
        "            out_words.append(' ')       \n",
        "        \n",
        "        else:\n",
        "            out_words.append(tknizer_eng.index_word[de_input.numpy()[0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:#or out_words[0] == out_words[-1]:\n",
        "            break\n",
        "            \n",
        "        de_input = tf.constant([[de_input.numpy()[0]]])\n",
        "\n",
        "    return ' '.join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F7r4FPTBDSW"
      },
      "outputs": [],
      "source": [
        "predictions_general = [predict_eng(i) for i in italic]  # prediction for random 1000 text data points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iHiLdROM23l",
        "outputId": "c28d6f60-92e0-4454-d314-7214fa782dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.39905063172540034\n"
          ]
        }
      ],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from  nltk.translate.bleu_score import sentence_bleu\n",
        "bleu_list = []\n",
        "for i in range(len(predictions)):\n",
        "    bleu_list.append(sentence_bleu(eng_out[i].split(), predictions_general[i].split()))\n",
        "\n",
        "print(sum(bleu_list)/len(bleu_list))   #bleu score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kN9ZWViQNMB"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaYPKZKz7BdG"
      },
      "outputs": [],
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "\n",
        "vocab_size_en = vocab_size_ita+1\n",
        "embedding_size_en = 50\n",
        "lstm_size_en = 256\n",
        "input_length_en = 20\n",
        "batch_size = 1024\n",
        "out_vocab_size_de = vocab_size_eng+1 \n",
        "embedding_dim_de = 50\n",
        "input_length_de = 20\n",
        "dec_units = 512\n",
        "score_fun = 'concat'\n",
        "att_units = 1024\n",
        "\n",
        "encoder_decoder_model_concat = encoder_decoder(vocab_size_en, embedding_size_en, lstm_size_en, input_length_en, batch_size,\n",
        "                                        out_vocab_size_de, embedding_dim_de, input_length_de, dec_units ,score_fun ,att_units)  # initializing encoder_decoder model with 'concat' score function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-nQge2R7RBU"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "encoder_decoder_model_concat.compile(optimizer=optimizer, loss=loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGzcA-HP7Bqf"
      },
      "outputs": [],
      "source": [
        "train_steps = train.shape[0]//1024      \n",
        "test_steps = test.shape[0]//1024         \n",
        "\n",
        "encoder_decoder_model_concat.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=train_dataloader, validation_steps=test_steps) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtMyPWseSKHJ"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "\n",
        "    test_source_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    if len(test_source_seq[0]) == 0:\n",
        "        return \"not a italic word\"\n",
        "    encoder = encoder_decoder_model_concat.layers[0]\n",
        "    \n",
        "    en_initial_states = encoder.initialize_states(1)\n",
        "\n",
        "    decoder_init = encoder_decoder_model_concat.layers[1].initialize_states(1)\n",
        "\n",
        "    encoder_output, state_h, state_c = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
        "\n",
        "    save_attention = []\n",
        "    out_words = []\n",
        "    while True:\n",
        "        predictions, state_h, state_c, attention_weights, context_vector = encoder_decoder_model_concat.layers[1].layers[0](de_input, encoder_output, decoder_init[0], decoder_init[1])\n",
        "        save_attention.append(attention_weights)\n",
        "\n",
        "        de_input = tf.argmax(predictions, -1)\n",
        "    \n",
        "        if de_input.numpy()[0] == 0:\n",
        "            out_words.append('')       \n",
        "        \n",
        "        else:\n",
        "            out_words.append(tknizer_eng.index_word[de_input.numpy()[0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:#or out_words[0] == out_words[-1]:\n",
        "            break\n",
        "            \n",
        "        de_input = tf.constant([[de_input.numpy()[0]]])\n",
        "\n",
        "    plot_attention(save_attention, input_sentence, out_words)\n",
        "    \n",
        "    return ' '.join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ToLh_V7JhaD"
      },
      "outputs": [],
      "source": [
        "predict(italic[400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gztZSWbfJhjv"
      },
      "outputs": [],
      "source": [
        "predict(italic[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztjzuoWCJjEd"
      },
      "outputs": [],
      "source": [
        "predict(italic[827])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUQ2rjF-JjIC"
      },
      "outputs": [],
      "source": [
        "def predict_eng(input_sentence):\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "\n",
        "    test_source_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    if len(test_source_seq[0]) == 0:\n",
        "        return \"not a italic word\"\n",
        "    encoder = encoder_decoder_model_concat.layers[0]\n",
        "    \n",
        "    en_initial_states = encoder.initialize_states(1)\n",
        "    \n",
        "    decoder_init = encoder_decoder_model_concat.layers[1].initialize_states(1)\n",
        "\n",
        "    encoder_output, state_h, state_c = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[tknizer_eng.word_index['<start>']]])\n",
        "\n",
        "    save_attention = []   # add attention weights for each each decoding step \n",
        "    out_words = []\n",
        "    while True:\n",
        "        predictions, state_h, state_c, attention_weights, context_vector = encoder_decoder_model_concat.layers[1].layers[0](de_input, encoder_output, decoder_init[0], decoder_init[1])\n",
        "        save_attention.append(attention_weights)\n",
        "\n",
        "        de_input = tf.argmax(predictions, -1)\n",
        "    \n",
        "        if de_input.numpy()[0] == 0:\n",
        "            out_words.append(' ')       \n",
        "        \n",
        "        else:\n",
        "            out_words.append(tknizer_eng.index_word[de_input.numpy()[0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:#or out_words[0] == out_words[-1]:\n",
        "            break\n",
        "            \n",
        "        de_input = tf.constant([[de_input.numpy()[0]]])\n",
        "\n",
        "    return ' '.join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW0uVrwjWgM4"
      },
      "outputs": [],
      "source": [
        "predictions_concat = [predict_eng(i) for i in italic] # prediction for random 1000 text data points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfNLA78OW7Lj"
      },
      "outputs": [],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from  nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "bleu_list = []\n",
        "for i in range(len(predictions_concat)):\n",
        "    bleu_list.append(sentence_bleu(eng_out[i].split(), predictions_concat[i].split()))\n",
        "\n",
        "print(sum(bleu_list)/len(bleu_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5KV-q3U15DA"
      },
      "outputs": [],
      "source": [
        "# observation \n",
        "# The prediction from encoder_decoder model with \"dot\" scoring function gives bleu score of 0.11 and \n",
        "# with \"general\" and \"concat\" scoring function blue socres are 0.049 and 0.16 respectively. we can observe that\n",
        "# encoder_decoder model with \"concat\" scoring gives high bleu followed by \"dot\" and \"general\".  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Final_Seq2SeqImplementation__Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
